{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "given dataset $D=\\left\\{(x^{(i)},y^{(i)})\\right\\}$\n",
    "\n",
    "decision tree is trying to pick $(feature, value)$ that partition the dataset to subsets\n",
    "\n",
    "after that partition, elements in each subsets is similar in total, i.e we gain certainty.\n",
    "\n",
    "continue the process, until we get subset that is very pure or partition too many times.\n",
    "\n",
    "we thus create a tree called the decision tree. \n",
    "\n",
    "when predicting, find leaf subset of that sample, then use typical value of leaf as prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## information gain\n",
    "\n",
    "we use entropy to measure the uncertainty of data.\n",
    "\n",
    "for classfication problem, assume $y_{(i)} \\in \\left\\{1,...,k\\right\\}$, we have the entropy of dataset $D$:\n",
    "\n",
    "$$H(D) = E(-log\\ p_{i}) = -\\sum_{i=1}^{k}p_{i}log\\ p_{i}$$\n",
    "\n",
    "$p_{i}$ is the frequency of i-th class, it defines the uncertainty of $D$.\n",
    "\n",
    "suppose we partition $D$ according to feature $A$ into $D_{1},...,D_{n}$, we have:\n",
    "\n",
    "$$H(D|A)=\\sum_{i=1}^{n}\\frac{\\#D_{i}}{\\#D}H(D_{i})$$\n",
    "\n",
    "that is: the uncertainty of $D$ after knowing $A$.\n",
    "\n",
    "information gain is uncertainty loss:\n",
    "\n",
    "$$g(D,A) = H(D) - H(D|A)$$\n",
    "\n",
    "decision tree ID3 choose feature $A$ that maximize $g(D,A)$ until:\n",
    "\n",
    "1. subset is empty\n",
    "2. information gain $g(D,A)\\le\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## information gain ratio\n",
    "\n",
    "if use information gain, we prefer feature $A$ such that $\\#A$ is large.\n",
    "\n",
    "more precisely, we prefer features that is uncertain\n",
    "\n",
    "$$H_{A}(D) =-\\sum_{i=1}^{n}\\frac{\\#D_{i}}{\\#D}log\\ \\frac{\\#D_{i}}{\\#D}$$\n",
    "\n",
    "defines that uncertainty, it is the entropy of viewing category of $A$ as labels.\n",
    "\n",
    "to fix that problem, we define the information gain ratio:\n",
    "\n",
    "$$g_{R}(D,A)=\\frac{g(D,A)}{H_{A}(D)}=\\frac{H(D)-H(D|A)}{H_{A}(D)}$$\n",
    "\n",
    "algorithm that uses $g_{R}(D,A)$ is C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pruning\n",
    "\n",
    "we need to pruning the decision tree $\\Rightarrow $ lower model's complexity $\\Rightarrow $ mitigate overfit\n",
    "\n",
    "suppose now we have a decision tree $T$, use $\\left | T \\right | $ to denote the number of leaves of $T$, and these leaves are $T_{1},...,T_{\\left | T \\right | }$.\n",
    "\n",
    "then entropy of leaf $t$: $H(T_{t})$\n",
    "\n",
    "total entropy of these leaves:\n",
    "\n",
    "$$C(T) = \\sum_{t=1}^{\\left | T \\right |} \\left | T_{t} \\right |H(T_{t})$$\n",
    "\n",
    "we want these minimize this entropy, and at the same time limit model's complexity, give rise to the loss function:\n",
    "\n",
    "$$C_{\\alpha}(T) = C(T) + \\alpha\\left | T \\right |$$\n",
    "\n",
    "in practice, pruning is from leaves to root.\n",
    "\n",
    "if pruning a node result in a decrease of the loss function, the operate this pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART-classification and regression tree\n",
    "\n",
    "CART can solve both the classification and regression problem.\n",
    "\n",
    "CART simply uses different strategies for them.\n",
    "\n",
    "for regression problem, we try to find feature $j$ and cutting point $s$ that minimize the square error:\n",
    "\n",
    "$$\\underset{j,s}{min}\\left[\\underset{c_{1}}{min}\\sum_{x_{i} \\in R_{1}(j, s)}(y_{i} - c_{1})^{2} + \\underset{c_{2}}{min}\\sum_{x_{i} \\in R_{2}(j, s)}(y_{i} - c_{2})^{2}\\right]$$\n",
    "\n",
    "rather than optimizing information gain or information gain ratio.\n",
    "\n",
    "CART optimize Gini-index when facing a classification problem:\n",
    "\n",
    "$$Gini(D) = E(1 - p_{i}) = \\sum_{i=1}^{k}p_{i}(1 - p_{i})$$\n",
    "\n",
    "here, rather than self-information $-log\\ p_{i}$ uses in entropy, we use $1 - p_{i}$ to indicate the information of event with probability $p_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:]  # petal length and width\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.1 (20210213.1702)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"351pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 351.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-310 347,-310 347,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M209.5,-306C209.5,-306 65.5,-306 65.5,-306 59.5,-306 53.5,-300 53.5,-294 53.5,-294 53.5,-235 53.5,-235 53.5,-229 59.5,-223 65.5,-223 65.5,-223 209.5,-223 209.5,-223 215.5,-223 221.5,-229 221.5,-235 221.5,-235 221.5,-294 221.5,-294 221.5,-300 215.5,-306 209.5,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M105,-179.5C105,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 105,-111.5 105,-111.5 111,-111.5 117,-117.5 117,-123.5 117,-123.5 117,-167.5 117,-167.5 117,-173.5 111,-179.5 105,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.09,-222.91C102.49,-211.65 94.23,-199.42 86.59,-188.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.39,-186 80.89,-179.67 83.59,-189.91 89.39,-186\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.14\" y=\"-200.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M286,-187C286,-187 147,-187 147,-187 141,-187 135,-181 135,-175 135,-175 135,-116 135,-116 135,-110 141,-104 147,-104 147,-104 286,-104 286,-104 292,-104 298,-110 298,-116 298,-116 298,-175 298,-175 298,-181 292,-187 286,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.91,-222.91C170.91,-214.01 177.33,-204.51 183.53,-195.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.44,-197.27 189.14,-187.02 180.64,-193.35 186.44,-197.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.9\" y=\"-207.86\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#4de88e\" stroke=\"black\" d=\"M196,-68C196,-68 99,-68 99,-68 93,-68 87,-62 87,-56 87,-56 87,-12 87,-12 87,-6 93,0 99,0 99,0 196,0 196,0 202,0 208,-6 208,-12 208,-12 208,-56 208,-56 208,-62 202,-68 196,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.81,-103.73C185.29,-94.97 179.45,-85.7 173.91,-76.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.78,-74.89 168.48,-68.3 170.85,-78.63 176.78,-74.89\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#843de6\" stroke=\"black\" d=\"M331,-68C331,-68 238,-68 238,-68 232,-68 226,-62 226,-56 226,-56 226,-12 226,-12 226,-6 232,0 238,0 238,0 331,0 331,0 337,0 343,-6 343,-12 343,-12 343,-56 343,-56 343,-62 337,-68 331,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.82,-103.73C247.26,-94.97 253.01,-85.7 258.48,-76.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.52,-78.64 263.82,-68.3 255.57,-74.95 261.52,-78.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f9f210b4a30>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "filenames": {
       "image/svg+xml": "/Users/facer/mynewbook/_build/jupyter_execute/06_decision_tree_8_0.svg"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"visualize using graphviz, need 1.pip install graphviz, 2.brew install graphviz\"\"\"\n",
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree_clf,\n",
    "                out_file=\"iris_tree.dot\",\n",
    "                feature_names=iris.feature_names[2:],\n",
    "                class_names=iris.target_names,\n",
    "                rounded=True,\n",
    "                filled=True\n",
    "               )\n",
    "\n",
    "Source.from_file(\"iris_tree.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.90740741, 0.09259259]]), array([1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]]), tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"criterion can switch from gini to entropy\"\"\"\n",
    "entropy_tree_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hyper-parameters for regularization\"\"\"\n",
    "regularized_tree_clf = DecisionTreeClassifier(max_depth=5,  # maximum depth of that tree\n",
    "                                              max_leaf_nodes=20,  # maximum number of leaf nodes\n",
    "                                              max_features=8,  # maximum number of features when splitting each node\n",
    "                                              min_samples_split=10,  # min number of samples of a node before it can split\n",
    "                                              min_samples_leaf=4,  # min number of samples of a leaf node\n",
    "                                              min_weight_fraction_leaf=0.01  # same as min_samples_leaf, but by weight frac\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CART(sklearn uses) can also regression\"\"\"\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"make moon dataset\"\"\"\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] max_leaf_nodes=2, min_samples_split=3 ...........................\n",
      "[CV]  max_leaf_nodes=2, min_samples_split=3, score=0.772, total=   0.0s\n",
      "[CV] max_leaf_nodes=2, min_samples_split=3 ...........................\n",
      "[CV]  max_leaf_nodes=2, min_samples_split=3, score=0.781, total=   0.0s\n",
      "[CV] max_leaf_nodes=2, min_samples_split=3 ...........................\n",
      "[CV]  max_leaf_nodes=2, min_samples_split=3, score=0.771, total=   0.0s\n",
      "[CV] max_leaf_nodes=2, min_samples_split=4 ...........................\n",
      "[CV]  max_leaf_nodes=2, min_samples_split=4, score=0.772, total=   0.0s\n",
      "[CV] max_leaf_nodes=2, min_samples_split=4 ...........................\n",
      "[CV]  max_leaf_nodes=2, min_samples_split=4, score=0.781, total=   0.0s\n",
      "[CV] max_leaf_nodes=2, min_samples_split=4 ...........................\n",
      "[CV]  max_leaf_nodes=2, min_samples_split=4, score=0.771, total=   0.0s\n",
      "[CV] max_leaf_nodes=5, min_samples_split=3 ...........................\n",
      "[CV]  max_leaf_nodes=5, min_samples_split=3, score=0.852, total=   0.0s\n",
      "[CV] max_leaf_nodes=5, min_samples_split=3 ...........................\n",
      "[CV]  max_leaf_nodes=5, min_samples_split=3, score=0.854, total=   0.0s\n",
      "[CV] max_leaf_nodes=5, min_samples_split=3 ...........................\n",
      "[CV]  max_leaf_nodes=5, min_samples_split=3, score=0.856, total=   0.0s\n",
      "[CV] max_leaf_nodes=5, min_samples_split=4 ...........................\n",
      "[CV]  max_leaf_nodes=5, min_samples_split=4, score=0.852, total=   0.0s\n",
      "[CV] max_leaf_nodes=5, min_samples_split=4 ...........................\n",
      "[CV]  max_leaf_nodes=5, min_samples_split=4, score=0.854, total=   0.0s\n",
      "[CV] max_leaf_nodes=5, min_samples_split=4 ...........................\n",
      "[CV]  max_leaf_nodes=5, min_samples_split=4, score=0.856, total=   0.0s\n",
      "[CV] max_leaf_nodes=10, min_samples_split=3 ..........................\n",
      "[CV]  max_leaf_nodes=10, min_samples_split=3, score=0.846, total=   0.0s\n",
      "[CV] max_leaf_nodes=10, min_samples_split=3 ..........................\n",
      "[CV]  max_leaf_nodes=10, min_samples_split=3, score=0.854, total=   0.0s\n",
      "[CV] max_leaf_nodes=10, min_samples_split=3 ..........................\n",
      "[CV]  max_leaf_nodes=10, min_samples_split=3, score=0.855, total=   0.0s\n",
      "[CV] max_leaf_nodes=10, min_samples_split=4 ..........................\n",
      "[CV]  max_leaf_nodes=10, min_samples_split=4, score=0.846, total=   0.0s\n",
      "[CV] max_leaf_nodes=10, min_samples_split=4 ..........................\n",
      "[CV]  max_leaf_nodes=10, min_samples_split=4, score=0.854, total=   0.0s\n",
      "[CV] max_leaf_nodes=10, min_samples_split=4 ..........................\n",
      "[CV]  max_leaf_nodes=10, min_samples_split=4, score=0.855, total=   0.0s\n",
      "[CV] max_leaf_nodes=20, min_samples_split=3 ..........................\n",
      "[CV]  max_leaf_nodes=20, min_samples_split=3, score=0.847, total=   0.0s\n",
      "[CV] max_leaf_nodes=20, min_samples_split=3 ..........................\n",
      "[CV]  max_leaf_nodes=20, min_samples_split=3, score=0.860, total=   0.0s\n",
      "[CV] max_leaf_nodes=20, min_samples_split=3 ..........................\n",
      "[CV]  max_leaf_nodes=20, min_samples_split=3, score=0.856, total=   0.0s\n",
      "[CV] max_leaf_nodes=20, min_samples_split=4 ..........................\n",
      "[CV]  max_leaf_nodes=20, min_samples_split=4, score=0.847, total=   0.0s\n",
      "[CV] max_leaf_nodes=20, min_samples_split=4 ..........................\n",
      "[CV]  max_leaf_nodes=20, min_samples_split=4, score=0.860, total=   0.0s\n",
      "[CV] max_leaf_nodes=20, min_samples_split=4 ..........................\n",
      "[CV]  max_leaf_nodes=20, min_samples_split=4, score=0.856, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'max_leaf_nodes': [2, 5, 10, 20],\n",
       "                          'min_samples_split': [3, 4]}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"grid search\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\"max_leaf_nodes\": [2, 5, 10, 20], \"min_samples_split\": [3, 4]}]\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(tree_clf, param_grid, cv=3, verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"using best estimator to predict\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = grid_search.predict(X_test)\n",
    "accuracy_score(y_true=y_test, y_pred=y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using multiple trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"generate 1000 subsets, each 100 instances\"\"\"\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "\n",
    "mini_sets = []\n",
    "\n",
    "rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)  \n",
    "# make train_size = len(X_train) - (len(X_train) - n_instances) = n_instances\n",
    "\n",
    "for mini_train_index, mini_test_index in rs.split(X_train):\n",
    "    X_mini_train = X_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    mini_sets.append((X_mini_train, y_mini_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8168704999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train each subset on grid_search.best_estimator_\"\"\"\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "forest = [clone(grid_search.best_estimator_) for _ in range(n_trees)]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"save all predictions\"\"\"\n",
    "Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n",
    "\n",
    "for tree_index, tree in enumerate(forest):\n",
    "    Y_pred[tree_index] = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"use majority vote, improve performance\"\"\"\n",
    "from scipy.stats import mode\n",
    "\n",
    "y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)\n",
    "accuracy_score(y_test, y_pred_majority_votes.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}