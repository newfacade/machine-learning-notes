{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means algorithm\n",
    "in the clustering problem, we are given a training set $\\left\\{x^{(1)},...,x^{(n)}\\right\\}$, and want to group the data into a few cohesive \"clusters\".\n",
    "\n",
    "here, $x^{(i)} \\in \\mathbb{R}^{d}$ as usual, but no labels $y^{(i)}$ are given, so this is an unsupervised learning problem.\n",
    "\n",
    "k-means clustering algorithm:\n",
    "\n",
    "1. initialize cluster centroids $\\mu_{1},...,\\mu_{k} \\in \\mathbb{R}^{d}$ randomly.\n",
    "2. repeat until convergence:<br>\n",
    "$\\quad$ for each $i$, set: \n",
    "$$c^{(i)} := \\underset{j}{argmin}\\left \\|x^{(i)} - \\mu_{j} \\right \\|^{2} $$\n",
    "$\\quad$ for each $j$, set:\n",
    "$$\\mu_{j} := \\frac{\\sum_{i=1}^{n}1\\left\\{c^{(i)}=j\\right\\}x^{(i)}}{\\sum_{i=1}^{n}1\\left\\{c^{(i)}=j\\right\\}}$$\n",
    "\n",
    "k is the number of clusters we want to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convergence\n",
    "\n",
    "define the distortion function to be:\n",
    "\n",
    "$$J(c,\\mu) = \\sum_{i=1}^{n}\\left \\|x^{(i)} - \\mu_{c^{(i)}} \\right \\|^{2}$$\n",
    "\n",
    "thus $J$ measures the sum of squared distances between each training example $x^{(i)}$ and the nearest cluster centroid $\\mu_{c^{(i)}}$\n",
    "\n",
    "k-means is exactly coordinate descent on $J$.\n",
    "\n",
    "the first step of k-means inner-loop:\n",
    "\n",
    "$\\quad$ minimize $J$ with respect to $c$ while holding $\\mu$ fixed.\n",
    "\n",
    "the second step of k-means inner-loop:\n",
    "\n",
    "$\\quad$ minimize $J$ with respect to $\\mu$ while holding $c$ fixed.\n",
    "\n",
    "but the distortion function $J$ is non-convex, so k-means may converge to local minimal.\n",
    "\n",
    "to tackle this local-minimal problem, we commonly run k-means many times, and choose the one gives the lowest $J(c, \\mu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/facer/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_labeled = 50\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train[: n_labeled], y_train[: n_labeled])\n",
    "\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k=50\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "X_digits_dist.shape  # sample distance from each centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
    "X_representative_digits = X_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_representative_digits = y_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_representative_digits, y_representative_digits)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]\n",
    "    \n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train, y_train_propagated)\n",
    "\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_closest = 75\n",
    "\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]  # distance of each sample\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
    "    \n",
    "partially_propagated = (X_cluster_dist != -1)\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)\n",
    "\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9701492537313433"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train_partially_propagated == y_train[partially_propagated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}